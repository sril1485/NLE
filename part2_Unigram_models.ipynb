{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#Reading the files\n",
    "f = open(\"sampletest.txt\", \"r\")\n",
    "samtext=f.read()\n",
    "v = open(\"sampledata.vocab.txt\", \"r\")\n",
    "voc=v.read()\n",
    "#Tokenize the text\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "samt=samtext\n",
    "#Removing the <s> and </s>\n",
    "samtext=re.findall(\"<s>(.*)</s>\",samtext)\n",
    "samtext=str(samtext)\n",
    "tokens=tokenizer.tokenize(samtext)\n",
    "#tokens1=tokenizer.tokenize(samt)\n",
    "vocab=voc.replace('\\n',' ')\n",
    "vocabulary=tokenizer.tokenize(vocab)\n",
    "for i in range(0,len(tokens)):\n",
    "    if tokens[i]=='d' or tokens[i]=='e':\n",
    "        tokens[i]=\"UNK\"\n",
    "#Count the frequency of the tokens\n",
    "import collections\n",
    "from collections import Counter\n",
    "wordcounts = Counter(tokens)\n",
    "count_of_tokens=list(wordcounts.values())\n",
    "labels=list(wordcounts.keys())\n",
    "#compute P(wi) = count(wi )/ N\n",
    "prob=[x/19 for x in count_of_tokens]\n",
    "#Print as table\n",
    "import pandas\n",
    "pandas.DataFrame(prob,labels)\n",
    "#Laplace smoothing\n",
    "smooth=[x+1 for x in count_of_tokens]\n",
    "smooth\n",
    "smooth_prob=[x/19 for x in smooth]\n",
    "pandas.DataFrame(smooth_prob,,labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
